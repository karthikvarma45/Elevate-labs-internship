# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bhOlYxQaMzXvsikHqoJ8rldf9MCW0kNN
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""#Load Of Data Set


* Here i taken a netflix data set.
* using read_csv i have read the data set
"""

df=pd.read_csv('/content/netflix_reviews.csv')

#view of data
df

"""#Previewing the first few rows
**Observation:**
The preview shows the first few rows of the data and helps us check if the file loaded correctly.
"""

df.head(5)

"""# Understanding the Structure of the Dataset

## Observation:
* The dataset contains 142312 rows × 8 columns representing various job-related features.
"""

df.shape

df.dtypes

# checking datatype of specific column
df['AT'].dtype

"""# Dataset Structure and Data Types

## Observation
The dataset contains 142312 records and 8 columns.
 - Out of the 8 columns:
    - 6 are categorical (object type), such as  reviewId,userName,conten,reviewCreatedVersion,at,app version

    - 2 are numerical (float64),(int64) such as score and thumbs up count                 

 - The dataset occupies approximately 8.7+mb of memory.
"""

df.info()

"""# Check and fix data types

* Convert all column names to uppercase
"""

df.columns = df.columns.str.upper()

"""#Finding the stastical values for the data"""

df.describe()

"""#Null Value Count Across All Columns
***Observations:***

Most columns have no missing values, indicating the dataset is generally clean and complete.

Content is missing for only 6 reviews, which is negligible and likely due to blank submissions.

reviewCreatedVersion and appVersion have around 25k missing values, which is expected because not all reviewers include app version details in their submissions.

User names and review IDs contain no missing values, ensuring clear identification of each review.

Date column (at) has no nulls, meaning every review is timestamped properly.

Numeric fields like score and thumbsUpCount also have no missing entries, making them fully usable for analysis.
"""

df.isnull().sum()

"""#Percentage of Missing Values
**Observations:**

* reviewCreatedVersion and appVersion each have ~17.3% missing values – many users do not report app version details when submitting reviews, which is normal for app store data.

* Content has only ~0.004% missing values – extremely small, likely due to users submitting empty reviews.

* All other columns have 0% missing values, meaning key fields like reviewId, userName, score, thumbsUpCount, and timestamp are fully complete.
"""

round(df.isnull().sum()/len(df)*100,2)

"""#Value Count Summary (Netflix Reviews Dataset)

--- Score ---

* Most common rating: 1-star (55,607 reviews) and 5-star (44,364 reviews) – highly polarized user sentiment.

* Least common rating: 2-star (12,528 reviews) – fewer users give moderate negative feedback.

--- App Version ---

* Most used versions:

8.141.1 build 13 51230 (~2,461 reviews)

* 9.40.0 build 7 63544 and similar recent builds

* Many older or less common versions appear only a few times.

--- User Activity ---

* Most frequent user entry: "A Google User" (30,272 times) – common for users without a Google profile name.

* Majority of other usernames appear only once → indicates a broad, diverse user base.

--- Review Content Frequency (Top Themes)

* Most used words: “the”, “and”, “netflix”, “but”, “this”

* Popular topics in reviews: movies, shows, watching experience, good, not working issues
"""

for col in df.select_dtypes(include=['object']).columns:
    print(f"\n--- Value counts for {col} ---")
    print(df[col].value_counts())

"""#Checking for Duplicates

##Observation:
As seen there are no duplicates found in the dataset.
"""

df.duplicated().sum()

k=df.drop_duplicates(inplace=True)

print(k)

df

df.isnull().sum()

"""#Deleting the unwanted columns


"""

df.dropna(inplace=True)

df.isnull().sum()
#The the data set is clean and composed



